\chapter{Observables and Operators}

\section{Operators and Measurement}

We've already seen lots of examples of \emph{observables} -- the spin components $S_x$, $S_y$, and $S_z$ are all examples of things that we can observe, as are things like position and momentum.  In the language of quantum mechanics: 
\[
\boxed{\text{A physical observable $A$ is represented by an operator $\hat{A}$.}}
\]

Wait, what exactly is an operator?  At the risk of being too simplistic, it's something that \emph{operates} on a quantum state, producing a new state.  Mathematically we can write this operation like
\begin{equation}
\hat{A} \ket{\psi} = \ket{\phi}.\footnote{Although the hat on the operator is standard, many textbooks drop it to reduce clutter in notation.  I think it's important to be able to easily distinguish an observable and an operator at a glance, especially for newcomers.}
\end{equation}
Actually, although in general the operator $\hat{A}$ produces a new state, sometimes the state it operates on is special and \emph{doesn't} change:
\begin{equation}
\label{eq_eigen}
\hat{A} \ket{\psi} = a \ket{\psi}.
\end{equation}
Instead of making a new state, it gives back the same state, but multiplied by a number $a$.  If you're familiar with linear algebra, you might recognize equation (\ref{eq_eigen}) as an \emph{eigenvalue equation}, with $a$ playing the role of the eigenvalue and the ket $\ket{\psi}$ being the eigenvector.   The eigenvalue is very important:
\\

\fbox{
  \parbox{0.9\textwidth}{
    The only possible result of a measurement of an observable $A$ is one of the eigenvalues $a_n$ of the corresponding operator $\hat{A}$.
  }
}

\subsection{The Operator $\hat{S_z}$}

That's a lot to take in on first reading, so let's do a full example.  We'll return to the observable $S_z$, which must have a corresponding operator $\hat{S}_z$.  We'll figure out how we can write this in a moment, but you might have realized we already know the eigenvalues of this operator: they must be $\hbar/2$ and $-\hbar/2$, since we know measurements of $S_z$ always return one of those two numbers.

That means that the eigenvalue equations -- two of them for two eigenvalues -- could be written as
\begin{equation}
\hat{S}_z \ket{+} = \frac{\hbar}{2} \ket{+} \quad \text{and} \quad \hat{S}_z \ket{-} = -\frac{\hbar}{2} \ket{-}.
\end{equation}
We can get a sense of what the operator $\hat{S}_z$ is by thinking of this in matrix notation -- the states $\ket{+}$ and $\ket{-}$ are column vectors, meaning $\hat{S}_z$ must be represented as a $2\times 2$ matrix (nothing else, when multiplied by a column vector, gives another column vector).  I don't know what the elements of the matrix are, so I'll write it out for now as
\[
\hat{S}_z \to \begin{pmatrix} a & b \\ c & d \end{pmatrix}.
\]

To find the unknown elements $a$, $b$, $c$, and $d$ (which could be complex), we can go back to the eigenvalue equations, this time in matrix notation.  For the eigenvalue $\hbar/2$, we have
\begin{equation}
\hat{S}_z \ket{+} = \frac{\hbar}{2} \ket{+} \to \begin{pmatrix} a & b \\ c & d \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \frac{\hbar}{2} \begin{pmatrix} 1 \\ 0 \end{pmatrix}.
\end{equation}
Multiplying out the left side gives
\[
\begin{pmatrix} a \\ c \end{pmatrix} = \begin{pmatrix} \hbar/2 \\ 0 \end{pmatrix},
\]
so we know that $a = \hbar/2$ and $c = 0$.  The other eigenvalue equation, for $-\hbar/2$, similarly gives $b = 0$ and $d = -\hbar/2$.  The operator $\hat{S}_z$, in matrix notation, is
\begin{equation}
\label{eq_sz_matrix}
\hat{S}_z \to \frac{\hbar}{2} \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}.
\end{equation}

There's a few things here we should notice -- in particular that $\hat{S}_z$ is a \emph{diagonal} matrix, with the eigenvalues as the diagonal elements.  Also note that the eigenvectors (the states $\ket{+}$ and $\ket{-}$) are unit vectors.  Both of these things arise because of the basis were using -- it's the $S_z$ basis!  In other words, in its own basis -- where the basis states are the eigenstates of the basis operator -- an operator will be diagonal with the eigenvalues along that diagonal.

\section{Matrix Representation}

In fact, any operator can be represented as a matrix; sticking with the $S_z$ basis, we can write a general operator $\hat{A}$ as a $2 \times 2$ matrix
\begin{equation}
\hat{A} \to \begin{pmatrix} a & b \\ c & d \end{pmatrix}.
\end{equation}

Now for something a little new.  Consider the calculation $\bra{+} \hat{A} \ket{+}$.  What exactly does this mean?  First we apply the operator $\hat{A}$ to the ket $\ket{+}$, getting a new state, and then apply the bra $\bra{+}$ to that new state:
\[
\bra{+} \Big( \hat{A} \ket{+} \Big) \to \begin{pmatrix} 1 & 0 \end{pmatrix} \begin{pmatrix} a & b \\ c & d \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 1 & 0 \end{pmatrix} \begin{pmatrix} a \\ b \end{pmatrix} = a.
\]
So the ultimate result is just a number -- $a$ in this case.  Similarly, you can show that $\bra{+}\hat{A} \ket{-} = b$, and so on.  That means we could be able to write our operator in matrix notation as
\begin{equation}
\hat{A} \to \begin{pmatrix} \bra{+}\hat{A}\ket{+} & \bra{+}\hat{A}\ket{-} \\ \bra{-}\hat{A}\ket{+} & \bra{-}\hat{A}\ket{-} \end{pmatrix}.
\end{equation}
This is just notation, but useful since we can see explicitly what the basis is.

It's easy enough to generalize this to any system; the matrix representation might have a different size than $2 \times 2$ (it might even be infinite), but the idea is the same.  In general we can write
\begin{equation}
\hat{A} \to \begin{pmatrix} 
a_{11} & a_{12} & a_{13} & \cdots \\ 
a_{21} & a_{22} & a_{23} & \cdots \\
a_{31} & a_{32} & a_{33} & \cdots \\
\vdots & \vdots & \vdots  & \ddots
\end{pmatrix},
\end{equation}
where $a_{ij} = \bra{i} \hat{A} \ket{j}$ and $\ket{i}$ and $\ket{j}$ are the basis states.  In this context we'll often call the $a_{ij}$s matrix elements.


\section{The Operators $\hat{S}_x$ and $\hat{S}_y$}

The matrix representation of the other two spin component operators are given by
\begin{equation}
\label{eq_sx_matrix}
\hat{S}_x \to \frac{\hbar}{2} \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}
\end{equation}
and 
\begin{equation}
\label{eq_sy_matrix}
\hat{S}_y \to \frac{\hbar}{2} \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix}.
\end{equation}
These are both written in the $S_z$ basis (notice that they're not diagonal).  If you'd like to know where these came from, feel free to work through the Stern-Gerlach results in Problem XXX.  What I'd rather do right now is ask the question: \emph{if we were to measure, say, $S_y$ on some particular state, what are the possible results we could get?}  We already know the answer in this case, but a lot of quantum mechanics boils down to figuring out the answer to this question for a variety of different observables and corresponding operators, so it's worth going through the process in detail.

The answer, as mentioned above, is given by the eigenvalues of the operator. You probably already know how to find eigenvalues fro your linear algebra course, but let's do it together nice and slow.  First, the eigenvalue equation is
\begin{equation}
\label{eq_eigeny}
\hat{S}_y \ket{\lambda} = \lambda \ket{\lambda},
\end{equation}
where $\lambda$ does double duty here, standing for the unknown eigenvalue as well as the corresponding eigenstate.  This might seem confusing at first, but we'll get used to it. 

We find the eigenvalues by solving the characteristic (or secular) equation , which looks like
\begin{equation}
\det | \textbf{S}_y - \lambda \textbf{I} | = 0.
\end{equation}
The bolded letter $\textbf{S}_y$ denote the matrix representation of the operator, and $\textbf{I}$ is the identity matrix.  Filling in the matrices gives
\[
\left| \begin{pmatrix} 0 & -i\hbar/2 \\ i\hbar/2 & 0  \end{pmatrix} - \begin{pmatrix} \lambda &  0 \\ 0 & \lambda \end{pmatrix} \right| = 0,
\]
or, after simplifying,
\[
\left| \begin{pmatrix} -\lambda & -i\hbar/2 \\ i\hbar/2 & -\lambda  \end{pmatrix} \right| = 0.
\]
Work out the determinant to get
\[
\lambda^2 - \left( \frac{\hbar}{2} \right)^2 = 0
\]
so that, finally, we can see that the two eigenvalues -- as expected! -- are $\lambda_1 = \hbar/2$ and $\lambda_2 = -\hbar/2$.  These two values are the only possible results we would get if we measured $S_y$ on any spin state.

What about the eigenstates?  To find these, we go back to the original eigenvalue equation (\ref{eq_eigeny}) and plug in each eigenvalue in turn.  For $\lambda = \hbar/2$, we have
\[
\hat{S}_y \ket{\lambda} = \frac{\hbar}{2} \ket{\lambda}.
\]
Writing the unknown state $\ket{\lambda}$ in matrix notation,
\begin{equation}
\ket{\lambda} \to \begin{pmatrix} \alpha \\ \beta \end{pmatrix},
\end{equation}
our job is to find the value of $\alpha$ and $\beta$ that satisfy the eigenvalue equation.  Here we go:
\[
\hat{S}_y \ket{\lambda} = \frac{\hbar}{2} \ket{\lambda} \to 
\frac{\hbar}{2} \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix} \begin{pmatrix} \alpha \\ \beta \end{pmatrix} = 
\frac{\hbar}{2}  \begin{pmatrix} \alpha \\ \beta \end{pmatrix},
\]
so
\[
\begin{pmatrix} -i \beta \\ i\alpha \end{pmatrix} =  \begin{pmatrix} \alpha \\ \beta \end{pmatrix}.
\]
This is really two equations for $\alpha$ and $\beta$, but they're the same equation -- we don't have enough information to get both values right now.  But we can at least solve for $\beta$ in terms of $\alpha$ and get
\[
\beta = i \alpha,
\]
making the eigenstate so far
\begin{equation}
\ket{\lambda} = \ket{+}_y \to \alpha \begin{pmatrix} 1 \\ i \end{pmatrix}.
\end{equation}
How, then, do we get the last unknown $\alpha$?  Well, every state must be normalized, so
\begin{equation}
_y \braket{+}{+}_y = 1. 
\end{equation}
In matrix notation, this becomes
\[
|\alpha|^2 \begin{pmatrix} 1 & -i \end{pmatrix} \begin{pmatrix} 1 \\ i \end{pmatrix} = |\alpha|^2 (2) = 1,
\]
so we'll take
\[
\alpha = \frac{1}{\sqrt{2}}
\]
and therefore
\begin{equation}
\ket{+}_y = \frac{1}{\sqrt{2}} \ket{+} + \frac{i}{\sqrt{2}} \ket{-} \to \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ i \end{pmatrix}.
\end{equation}

Feel free to go through the same process to get the spin down eigenstate; it turns out to be
\begin{equation}
\ket{-}_y = \frac{1}{\sqrt{2}} \ket{+} - \frac{i}{\sqrt{2}} \ket{-} \to \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ -i \end{pmatrix}.
\end{equation}
Problem XXX will get you to go through the process for $S_x$.



\section{Spin in a General Direction, $\hat{S}_n$}

At this point I just want to give you some more operators and figure out their eigenvalues and eigenstates, partly so we can get the practice and partly so we can use them again later.  First up, suppose we rotate our usual Stern-Gerlach device to some random orientation so that the magnetic field points in the direction of $\vec{n}$ as shown in Figure XXX.  The angles $\theta$ (the polar angle) and $\phi$ (the azimuthal angle) are the usual spherical coordinates, and we'll make $\vec{n}$ a unit vector so it has a length of one.  That means in terms of the Cartesian unit vectors $\unit{x}$, $\unit{y}$, and $\unit{z}$, we can write
\begin{equation}
\vec{n} = \sin \theta \cos \phi \, \unit{x} + \sin \theta \sin \phi \, \unit{y} + \cos \theta \, \unit{z}.
\end{equation}

Suppose we measure the spin of a particle along this direction; let's call the observable $S_n$, where
\begin{equation}
S_n = \vec{S} \cdot \vec{n} = S_x \sin \theta \cos \phi  + S_y \sin \theta \sin \phi + S_z \cos \theta.
\end{equation}
The operator associated with this observable is, of course, the exact same except with hats on the operators, so we have\footnote{Okay, we have to be a little careful now distinguishing unit vectors from operators, both of which have hats.  Things should be clear from context.}
\begin{equation}
\label{eq_Sn}
\hat{S}_n = \hat{\vec{S}} \cdot \vec{n} = \hat{S}_x \sin \theta \cos \phi  + \hat{S}_y \sin \theta \sin \phi  + \hat{S}_z \cos \theta.
\end{equation}
To write this operator in matrix notation, we just fill in the matrices for $\hat{S}_x$, $\hat{S}_y$, and $\hat{S}_z$ and add them together to get
\begin{equation}
\label{eq_Sn_matrix}
\hat{S}_n \to \frac{\hbar}{2} \begin{pmatrix} \cos \theta & \sin \theta \, e^{-i\phi} \\ \sin \theta \, e^{i\phi} & -\cos \theta \end{pmatrix}
\end{equation}
(see Problem \ref{prob_Sn}).

This is a new operator we've never seen before, and anytime we're faced with a new operator, we should always find its eigenvalues and eigenstates -- remember, the eigenvalues of the operator answer the question of what we get when we measure the observable, so they're pretty important, and we'll see that the eigenstates play just as important a role.  But wait -- we \emph{already} know the eigenvalues!  They \emph{have} to be $\hbar/2$ and $-\hbar/2$, just like $\hat{S}_x$ or any other component.  After all, changing the direction of the magnetic field by rotating the device is the exact same operation as changing our coordinate system, and that should affect the actual results we get.

So, fine, we know the eigenvalues (you can check that we're correct in Problem \ref{prob_Sn}); what about the eigenstates?  You need more practice than I do, so try on your own (that's Problem XXX again), and I'll give you just the answers for now.  The eigenstates are (with notation that should be clear by now; the ket $\ket{+}_n$ is the state that goes with $+\hbar/2$ and similarly for the eigenvalue $-\hbar/2$)
\begin{equation}
\label{eq_plus_n}
\ket{+}_n = \cos (\theta/2) \, \ket{+} + \sin (\theta/2) \, e^{i\phi} \, \ket{-}
\end{equation}
and
\begin{equation}
\label{eq_minus_n}
\ket{-}_n = \sin (\theta/2) \, \ket{+} - \cos (\theta/2) \, e^{i\phi} \, \ket{-}.
\end{equation}
Remember, all this is explicitly in the $S_z$ basis.

By the way, if you were wondering how we make some ``general spin state'' $\ket{\psi}$ with some specific set of coefficients, this is how:  orient the Stern-Gerlach device at just the correct angles $\theta$ and $\phi$ that give you those coefficients.  Problem XXX will ask you to do this.


\section{The $\hat{S}^2$ Operator}

All of the spin operators we've seen so far have be \emph{components} of the spin angular momentum \emph{vector}.  We know that we can't simultaneously know all three components, but it turns out we can measure the total magnitude of the spin; in fact, we usually work with the square,
\begin{equation}
S^2 = S_x^2 + S_y^2 + S_z^2.
\end{equation}
At the risk of repeating things, the operator $\hat{S}^2$ is of course
\begin{equation}
\hat{S}^2 = \hat{S}_x^2 + \hat{S}_y^2 + \hat{S}_z^2,
\end{equation}
and we can determine what it looks like in the $S_z$ basis using matrix notation.  Substituting from equations (\ref{eq_sz_matrix}), (\ref{eq_sx_matrix}), and (\ref{eq_sy_matrix}), we see that
\begin{equation}
\hat{S}^2 \to \left[ \frac{\hbar}{2} \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix} \right]^2 + 
\left[ \frac{\hbar}{2} \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix} \right]^2 + 
\left[ \frac{\hbar}{2} \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix} \right]^2
\end{equation}
or
\begin{equation}
\hat{S}^2 \to \frac{3}{4} \hbar^2 \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} 
\end{equation}

But you might recognize this matrix as the identity matrix -- and it's diagonal, which means we can just read off the eigenvalues:  there's two but they're the same, $3\hbar^2/4$.  That means that \emph{every} measurement of $S^2$ (or just the magnitude $S$) will return $3\hbar^2/4$ (or $\sqrt{3} \hbar /2$).  The eigenstates are simple, too, give the diagonal matrix -- they're the basis states $\ket{+}$ and $\ket{-}$.

\section{The Projection and Identity Operators}

We've seen that one way to combine two quantum states is the \emph{inner product}, which is related to probability, but there's also another way to combine two states called an \emph{outer product}, which takes the form
\[
\ket{\phi}\bra{\psi}.
\]

For example, consider the so-called \emph{projection operators}, formed from the outer product of a basis state.  One possibility is written as
\begin{equation}
\hat{P}_+ = \ket{+} \bra{+}, 
\end{equation}
with the other (in our two basis-state system) as
\begin{equation}
\hat{P}_- = \ket{-} \bra{-}.
\end{equation}
Notice that these really are operators:  the bra will act on another state, leaving some number times the ket.  

Let's see what $\hat{P}_+$ does to a general state $\ket{\psi} = a\ket{+} + b\ket{-}$:
\[
\hat{P}_+ \ket{\psi} = \ket{+} \bra{+} \ket{\psi} = \ket{+} \bra{+} \Bigl( a\ket{+} + b\ket{-} \Bigl) = a \ket{+}.
\]
We can see why it's called a projection operator:  applying it to a state gives us a new state that is how much ``spin up'' the original state was times the spin up state itself.  Similarly, of course, for $\hat{P}_-$:
\[
\hat{P}_- \ket{\psi} = b \ket{-}.
\]

What are the matrix representations of $\hat{P}_\pm$?  In the $S_z$ basis,
\begin{equation}
\hat{P}_+ \to 
\begin{pmatrix}
\bra{+} \hat{P}_+ \ket{+} & \bra{+} \hat{P}_+ \ket{-} \\
\bra{-} \hat{P}_+ \ket{+} & \bra{-} \hat{P}_+ \ket{-}
\end{pmatrix}
 = 
\begin{pmatrix}
1 & 0 \\ 0 & 0
\end{pmatrix}
\end{equation}
and
\begin{equation}
\hat{P}_- \to 
\begin{pmatrix}
0 & 0 \\ 0 & 1
\end{pmatrix}.
\end{equation}

Here's another operator while we're at it:  I'll define the \emph{identity operator} as 
\begin{equation}
\hat{1} = \hat{P}_+ + \hat{P}_-.
\end{equation}
Take a look at the effect it has on a state:
\[
\hat{1} \ket{\psi} = (\hat{P}_+ + \hat{P}_-) \ket{\psi} = \hat{P}_+\ket{\psi} + \hat{P}_-\ket{\psi} = a\ket{+} + b\ket{-}.
\]
But this is exactly the state $\ket{\psi}$ that we started with -- so there's no change at all.

It's even clearer if we work out the matrix representation; I'll let you check, but of course it's the identity matrix,
\begin{equation}
\hat{1} \to \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix}.
\end{equation}

\section{Hermitian Operators}

We've just gone through lots of different operators, so it's time to circle back to the start of this chapter.  We said there that an operator acts on a state and produces a new state:
\[
\hat{A} \ket{\psi} = \ket{\phi}.
\]
How does the operator act on a \emph{bra}?  In general, it produces a \emph{different} state,
\begin{equation}
\bra{\psi} \hat{A} = \bra{\xi}.
\end{equation}
Notice that the operator sits to the right of the bra and acts to the left, and that the state that it produces when acting on $\bra{\psi}$ is \emph{not} the same state as the operator acting on the \emph{ket}; that is, $\ket{\phi}$ and $\ket{\xi}$ are different quantum states.

However, if we instead act on the bra $\bra{\psi}$ with a different operator, $\hat{A}^\dagger$ -- called the Hermitian adjoint of $\hat{A}$ -- then we \emph{do} get the state $\bra{\phi}$:
\begin{equation}
\bra{\psi} \hat{A}^\dagger = \bra{\phi}.
\end{equation}

Wait, what exactly is a Hermitian adjoint?  To see, imagine taking the inner product of the state $\ket{\phi} = \hat{A} \ket{\psi}$ with some other state $\ket{\beta}$,
\[
\braket{\phi}{\beta},
\]
and of course we can flip the order by taking the complex conjugate,
\[
\braket{\phi}{\beta} = \braket{\beta}{\phi}^*.
\]
But $\bra{\phi} = \bra{\psi}\hat{A}^\dagger$ and $\ket{\phi} = \hat{A} \ket{\psi}$, so we can write
\[
\bra{\psi}\hat{A}^\dagger \ket{\beta} = \bra{\beta} \hat{A} \ket{\psi}^*.
\]
Remember, these operations are called matrix elements, so this tells us that the matrix representation pf $\hat{A}^\dagger$ is the \emph{transpose} and complex conjugate of $\hat{A}$.

One last thing, but it's really important:  sometimes it turns out that $\hat{A}^\dagger = \hat{A}$ (or, in matrix notation, the operator is equal to its transpose conjugate).  In this case we say that the operator $\hat{A}$ is \emph{Hermitian}.  In fact,
\[
\boxed{\text{Every physical observable is represented by a Hermitian operator.}}
\]
That's important, since you can prove that a Hermitian operator will always have \emph{real} eigenvalues and that the eigenvectors will always be complete.

\section{The Ladder Operators}

So far every operator we've talked about has been Hermitian -- go ahead and check.  As a last example for the chapter, and one we'll make use of later, consider this mix of the operators $\hat{S}_x$ and $\hat{S}_y$:
\begin{equation}
\hat{S}_+ \equiv \hat{S}_x + i\hat{S}_y \quad \text{and} \quad \hat{S}_- \equiv \hat{S}_x - i\hat{S}_y.
\end{equation}
These are called ``ladder operators,'' with $\hat{S}_+$ begin the \emph{raising} operator and $\hat{S}_-$ the \emph{lowering} operator.

What do these operators do?  It's easiest to see in matrix notation, which is straightforward to figure out -- just add the spin matrices together in the appropriate way.  The raising operator is
\begin{equation}
\hat{S}_+ \to \hbar \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix}
\end{equation}
and the lowering operator is
\begin{equation}
\hat{S}_- \to \hbar \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix}.
\end{equation}
I think you can see at a glance that these matrices are not Hermitian -- try taking their transpose.  But while we're looking at them, note that $\hat{S}_+^\dagger = \hat{S}_-$; they're \emph{Hermitian conjugates}.

Let's see what the raising operator does to our basis states, starting with spin up,
\[
\hat{S}_+ \ket{+} \to \hbar \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix} = \mathbf{0},
\]
and then spin down,
\[
\hat{S}_+ \ket{-} \to \hbar \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \begin{pmatrix} 0 \\ 1 \end{pmatrix} = \hbar \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \hbar \ket{+}.
\]
What's going on here?  The raising operator ``raises'' the spin down state to become spin up (times a constant), but, since there's no higher spin state than spin up, when $\hat{S}_+$ acts on that, it just gives zero.

Can you guess how the lowering operator will act?  It should ``lower'' the spin up state, and give us zero for the spin down state, and it does:
\[
\hat{S}_- \ket{+} \to \hbar \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix} \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \hbar \begin{pmatrix} 0 \\ 1 \end{pmatrix} = \hbar \ket{-},
\]
and
\[
\hat{S}_- \ket{-} \to \hbar \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix} \begin{pmatrix} 0 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix} = \mathbf{0}.
\]

\section*{Problems}
\addcontentsline{toc}{section}{Problems}
\markright{Problems}%

\begin{problem}[The $\hat{S}_n$  Operator]
\label{prob_Sn}

(a) Given the form of the operator $\hat{S}_n$ in equation (\ref{eq_Sn}), show that the matrix formulation is as in equation (\ref{eq_Sn_matrix}).

(b) Using the matrix representation, find the eigenvalues and eigenstates of $\hat{S}_n$.
\end{problem}

\begin{problem}[Spin-1]

Until now, we've been playing with spin-1/2 particles -- electrons, protons, neutrons, and, apparently, silver atoms.  However, our lab has just been gifted a new set of photons to play with, and photons are particles that have a spin of one.  Sure enough, when we send them through a Stern-Gerlach type experiment to measure the photon's spin component along the $z$-direction, we get three possible results rather than two:
\begin{itemize}
\item $S_z = +\hbar$
\item $S_z = 0$
\item $S_z = -\hbar$.
\end{itemize}
This is the hallmark of a spin-1 system, and our goal in this assignment is to fully explore it.

(a) To start, we need to pick a basis, and given our experience with the $S_z$ basis in spin-1/2, we should use that here, too.  Write down the following three things:  (i) the three basis states (call them $|1\rangle$, $|0\rangle$, and $|-1\rangle$, corresponding to measuring $+\hbar$, $0$, and $-\hbar$ respectively), as kets and in matrix notation; (ii) the eigenvalue equations (all three of them since we have three eigenvalues) for the operator $\hat{S}_z$; and (iii) the matrix representation of the operator $\hat{S}_z$.

(b) Recall the raising and lowering operators we defined in class:
\[
\hat{S}_+ \equiv \hat{S}_x + i\hat{S}_y \quad \text{and} \quad \hat{S}_- \equiv \hat{S}_x - i\hat{S}_y.
\]
After painstaking theoretical work, you finally figure out what they do when operating on our basis states:\footnote{Although it's obvious that they'll raise and lower the states, the $\sqrt{2}$ factor is a little harder; come see me if you're curious.}
\begin{align*}
\hat{S}_+ \ket{1} = 0 \quad & \quad \hat{S}_- \ket{1} = \sqrt{2} \hbar \ket{0} \\
\hat{S}_+ \ket{0} = \sqrt{2} \hbar \ket{1} \quad & \quad  \hat{S}_- \ket{0} = \sqrt{2} \hbar \ket{-1} \\
\hat{S}_+ \ket{-1} = \sqrt{2} \hbar \ket{0} \quad & \quad  \hat{S}_- \ket{-1} = 0.
\end{align*}

Use this to write out the matrix representation of $\hat{S}_+$ and $\hat{S}_-$, and then use their definition above to find the matrix representation of $\hat{S}_x$ and $\hat{S}_y$ (that was our ultimate goal here).

(c) Now that we have $\hat{S}_x$ and $\hat{S}_y$, we need to find their eigenvalues and eigenvectors.  Do so, and write out the eigenstates in ket form and in matrix form.

(d) We now have a complete theory of spin-1, which means we can finally so some interesting experiments with those photons.  Suppose you arrange your apparatus to prepare the photons in the state
\[
\ket{\psi} = \ket{1} - 3\ket{0} + 2i\ket{-1}.
\]
\begin{enumerate}[label=\roman*.	]
\item You prepare 1000 photons this way, and measure their spin component $S_z$.  What values do you measure, and how many photons of the 1000 yield each result?
\item You collect all the photons that had mesaurements of $S_z = -\hbar$.  You then measure $S_x$ on those; what do you get, and what is the number of photons for each possible result?
\item If, on the original set of 1000 photons, you had instead measured $S_y$, what would have been the average (i.e., expectation value) of all results?
\end{enumerate}

\end{problem}



